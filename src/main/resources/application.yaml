spring:
  ai:
    ollama:
      base-url: http://localhost:11400
      chat.options:
        model: mistral
        temperature: 0.7
#    mistralai:
#      api-key: ${MISTRALAI_API_KEY}
    vectorstore.qdrant:
      host: ${QDRANT_HOST:localhost}
      port: ${QDRANT_PORT:6334}
      collection-name: ai
      initialize-schema: true
  application.name: ai
  docker.compose:
    enabled: true
    lifecycle-management: start_and_stop
  threads.virtual.enabled: true
